#! /usr/bin/env python
#! /usr/bin/env python
# -*- coding: utf-8 -*-

### includes ###

import sys
import os
import urllib, urllib2
import time
import collections
import hashlib
import cStringIO
import subprocess
import logging
try:
  import simplejson as json
except ImportError:
  import json

try:
  from tornado import web
except:
  print >> sys.stderr, """This software requires Tornado. Please, install the python-tornado package from your distribution."""

try:
  from tornadio2 import SocketConnection, TornadioRouter, SocketServer, event
except:
  print >> sys.stderr, """This software requires Tornadio2. Please, install Tornadio2 from here: https://github.com/mrjoes/tornadio2"""

from biconcor import BiconcorProcess, parse_biconcor_output_into_json_struct



### global vars ###


# root directory of the server
ROOT = os.path.normpath(os.path.dirname(__file__))


# BiconcorProcess objects, indexed by the language pair
biconcor_processes = {}



### generic utils ###


def toutf8(string):
  """ strings in python are unicode. We need to convert strings to uft8 before """
  return string.encode('utf-8')


class MRUDict (collections.MutableMapping):
    """ Container class that acts as a dictionary but only remembers the K items that were last accessed """

    def __init__ (self, max_size, items=()):
        self.max_size = int (max_size)
        self.impl = collections.OrderedDict ()
        if isinstance (items, dict):
            items = items.iteritems()
        for key,value in items:
            self[key] = value

    def __len__ (self):
        return len(self.impl)
    def __iter__ (self):
        return iter (self.impl)
    def __delitem__ (self, key):
        del self.impl[key]

    def __contains__ (self, key):
        if key in self.impl:
            # re-insert the item so that it is now the MRU item
            val = self.impl.pop (key)
            self.impl[key] = val
            return True
        else:
            return False

    def __getitem__ (self, key):
        # re-insert the item so that it is now the MRU item
        val = self.impl.pop (key)
        self.impl[key] = val
        return val

    def __setitem__ (self, key, val):
        while len(self.impl) >= self.max_size:
            # delete the LRU item
            self.impl.popitem (last=False)
        self.impl[key] = val


### Cached searchgraphs (index: source sentence. Remember to include language pair later)
searchGraph = MRUDict (1000)

### connection to server.py ###

server_py_cache = MRUDict (1000)

def request_to_server_py (text, action='translate', use_cache=False):
  port = 8644
  if isinstance (text, unicode):
    text = text.encode ('UTF-8')
  url = 'http://127.0.0.1:%d/%s?%s' % (
    port,
    action,
    'q=%s&key=0&source=xx&target=xx&sg=true' % urllib.quote_plus(text),
    )
  print url
  if use_cache:
    from_cache = server_py_cache.get (url)
    if from_cache is not None:
      return from_cache
  req = urllib2.Request (url, '', {'Content-Type': 'application/json'})
  f = urllib2.urlopen (url)
  output_struct = json.load(f)
  f.close()
  if use_cache:
    server_py_cache[url] = output_struct
  return output_struct

def request_translation_and_searchgraph(source, returnTranslation = True):
    #global searchGraph
    translation = request_to_server_py (source, use_cache=True)

    target = translation[u'data'][u'translations'][0][u'translatedText']
    sg = translation[u'data'][u'translations'][0][u'searchGraph']

    sgId = hashlib.sha224(source).hexdigest() # unique searchgraph id generated by source

    output = cStringIO.StringIO()
    firstLine = True
    for row in sg:
        if firstLine:
            output.write("hyp,stack,back,score,transition,recombined,forward,fscore,covered,out\n")
            output.write(str(row["hyp"])+','+str(row["stack"])+',0,0,-1,'+ str(row["forward"])+','+str(row["fscore"])+'\n')
            firstLine = False
        else:
            try:
                output.write(str(row["hyp"])+','+str(row["stack"])+','+str(row["back"])+','+str(row["score"])+','+str(row["transition"])+','+str(row["recombined"])+','+str(row["forward"])+','+str(row["fscore"])+','+ str(row["cover-start"])+','+str(row["cover-end"])+',"'+toutf8(row["out"])+'"\n')
            except:   # if no 'recombined' in line
                output.write(str(row["hyp"])+','+str(row["stack"])+','+str(row["back"])+','+str(row["score"])+','+str(row["transition"])+',-1,'+ str(row["forward"])+','+str(row["fscore"])+','+str(row["cover-start"])+','+str(row["cover-end"])+',"'+toutf8(row["out"])+'"\n')

    searchGraph[sgId] = output.getvalue()
    output.close()
    if returnTranslation:
        # needs to have >1 translations in Chrome (works ok for Firefox), check out why.
        res = { 'data': { 'source': source,
                        'nbest': ( { 'target': target  },
                                   { 'target': target  }
                                 )
                        } }
        return res


### main Tornadio class ###

# This class will handle our client/server API. Each function we would like to
# exports needs to be decorated with the @event decorator (see example below).

class MinimalConnection(SocketConnection):

    def emit (self, *args, **kwargs):
      """ Print out everything we emit to stdout for debugging. This method can be commented out to disable this. """
      print "emit(%s)" % ', '.join (
        ['%r' % a for a in args] +
        ['%s=%r' % i for i in kwargs.iteritems()]
        )
      return super(MinimalConnection,self).emit (*args, **kwargs)

    # @event is a decorator that exports the function to be used with the
    # socket.io javascript client.
    @event
    # the on_open event is called when a socket.io connection  is opened.
    # This is the place to initialize session variables
    def on_open(self, info):
      print >> sys.stderr, "Connection Info", repr(info.__dict__)
      self.config = { 'enabled': True }

    @event
    # the on_close event is called when a socket.io connection is closed.
    # This is the place to delete session variables
    def on_close(self):
      del self.config

    # PING
    # echos time stamp
    @event
    def ping(self, data):
      print "called ping", data
      res = { 'data': data }
      self.emit('pingResult', res)

    # GET SERVER CONFIG
    # does not seem to be used by anything, so we just return 0
    @event
    def getServerConfig(self):
      print "called getServerConfig"
      res = { 'data' : 0 }
      self.emit('getServerConfigResult', res)

    # CONFIGURE
    @event
    def configure(self, data):
      print "called configure", data

    # DECODE
    @event
    def decode(self, data):
      print "called decode", data
      res = request_translation_and_searchgraph(data['source'])
      self.emit('decodeResult', res)

    # START SESSION
    @event
    def startSession(self, data):
      print "called startSession", data

    # REJECT SUFFIX
    @event
    def rejectSuffix(self, data):
      print "called rejectSuffix", data

    # SET PREFIX
    @event
    def setPrefix(self, data):
      #global searchGraph
      start_time = time.time()
      print "called setPrefix", data

      errors = []
      target = data[u'target']
      caretPos = data[u'caretPos']

      prefix = target[0:caretPos]
      prefix = toutf8(prefix)

      try:
        # tokenize prefix (change of var name to "userInput" because "prefix" needs to be returned to the client)
        pProcess  = request_to_server_py(prefix, action='tokenize')
        userInput = pProcess[u'data'][u'translations'][0][u'tokenizedText']
        #truecase
        pProcess  = request_to_server_py(toutf8(userInput), action='truecase')
        userInput = pProcess[u'data'][u'translations'][0][u'truecasedText']
        userInput = toutf8(userInput)
      except:
        userInput = prefix

      sgId = hashlib.sha224(data[u'source']).hexdigest()

      if searchGraph.get(sgId) is None:
        request_translation_and_searchgraph(data['source'], returnTranslation = False)

      try:
        args = ['./predict', userInput ]
        #logging.debug(' '.join(args))
        p = subprocess.Popen(args, stdin=subprocess.PIPE, stdout=subprocess.PIPE, stderr=subprocess.PIPE, preexec_fn = lambda: os.nice(10),)

        p.stdin.write(searchGraph[sgId])
        p.stdin.close()

        t_now = time.time()
        seconds_passed = 0

        while(p.poll() is None and seconds_passed < 10):
            seconds_passed = time.time() - t_now
        prediction = ''
        logging.debug(p.poll())
        if p.poll() is None:
            # in case the process did not complete, kill it
            #logging.debug('prediction timed out')
            p.kill()
            prediction = ''
        else:
            for line in iter(p.stdout.readline, ''):
                prediction += line

      except Exception as e:
        prediction = ''
        errors.append(str(e))

      print prediction
      #postprocessing
      trueCase = prediction[:1]  #true case of the first character of the prediction
      pProcess   = request_to_server_py(prediction, 'detokenize')
      prediction = pProcess[u'data'][u'translations'][0][u'detokenizedText']

      pProcess   = request_to_server_py(toutf8(prediction), 'detruecase')
      prediction = pProcess[u'data'][u'translations'][0][u'detruecasedText']
      prediction = toutf8(prediction)
      prediction = trueCase + prediction[1:] #substitute the first char to its real case
      elapsed_time = time.time() - start_time
      res = { 'errors': errors,
              'data': {
                    'caretPos': caretPos,
                    'elapsedTime': elapsed_time,
                    'source': data['source'] ,
                    'sourceSegmentation' : ( (0,5), (6,14), (15,17), (18,23), (23,24) ),
                    'nbest': [ { 'target': prefix + prediction, 'elapsedTime': elapsed_time, 'author': 'ITP', 'targetSegmentation': ( (0,5), (6,14), (15,17), (18,23), (23,24), (25,30),(31,32),(33,34),(35,36),(37,38) ) }
                             ]
                      } }
      self.emit('setPrefixResult', res)

    @event
    def Validate(self,data):
        print "called Validate", data
    # getAlignments
    @event
    def getAlignments(self, data):
      print "called getAlignments", data

    # getTokens
    @event
    def getTokens(self, data):
      print "called getTokens", data
      errors = []
      res = { 'errors': errors,
              'data': {
                    'source': data['source'] ,
                    'sourceSegmentation' : ( (0,5), (6,14), (15,17), (18,23), (23,24) ),
                    'target': data['target'], 'targetSegmentation': ( (0,5), (6,14), (15,17), (18,23), (23,24), (25,30),(31,32),(33,34),(35,36),(37,38) )
                    } }
      self.emit('getTokensResult', res)

    @event
    def getConfidences(self, data):
      print "called getConfidences", data

    @event
    def setReplacementRule(self, data):
      print "called setReplacementRule", data

    @event
    def getValidatedContributions(self, data):
      print "called getValidatedContributions", data

    @event
    def biconcor (self, data):
      print "called biconcor", data
      lang_pair = 'en-de' # '%s-%s' % (data['srcLang'], data['tgtLang'])
      src_phrase = data['srcPhrase']
      biconcor_proc = biconcor_processes.get (lang_pair)
      if biconcor_proc is None:
        biconcor_proc = biconcor_processes[lang_pair] = BiconcorProcess (lang_pair)
      if not biconcor_proc.is_warm():
        self.emit ('biconcorResult', {
            'errors': None,
            'data': {
              'warm': False,
              'srcPhrase': src_phrase,
              }
            })
      concor_struct = parse_biconcor_output_into_json_struct (
        biconcor_proc.get_concordance (src_phrase),
        detokenize_and_postprocess = lambda tokens: \
          request_to_server_py (' '.join(tokens), action='detokenize', use_cache=True) \
          ['data']['translations'][0]['detokenizedText'],
        )
      self.emit ('biconcorResult', {
          'errors': None,
          'data': {
            'warm': True,
            'srcPhrase': src_phrase,
            'concorStruct': concor_struct,
            }
          })


# We setup our connection handler. You can define different endpoints
# for additional socket.io services.
class RouterConnection(SocketConnection):
    __endpoints__ = {
                      '/cat': MinimalConnection
                    }

    def on_open(self, info):
        print 'Router', repr(info)


# Create tornadio router
MinimalRouter = TornadioRouter(RouterConnection)



### cmd-line parsing and server init ###

if __name__ == "__main__":

    if len(sys.argv) == 1:
      port = 8660
    elif len(sys.argv) == 2:
      port = int(sys.argv[1])
    else:
      print >> sys.stderr, "usage: %s [port]" % sys.argv[0]
      sys.exit(1)

    LOG_FILENAME = 'catserver.log'
    logging.basicConfig(filename=LOG_FILENAME,level=logging.DEBUG,)

    # Create socket application
    application = web.Application(
        MinimalRouter.apply_routes([
                                      # Here you can add more handlers for
                                      # traditional services,
                                      # like a file or ajax server. See
                                      # Tornado documentation for that
                                      # (r"/", IndexHandler),
                                      # (r"/js/(.*)", JsHandler),
                                      # (r"/css/(.*)", CssHandler),
                                      # (r"/examples/(.*)", ExampleHandler)
                                    ]),
        # if you want the flash transport to work you need to place the
        # flashpolicy.xml and WebSocketMain.swf in the correct place (see docs)
        #flash_policy_port = 843,
        #flash_policy_file = os.path.join(ROOT, 'flashpolicy.xml'),
        socket_io_port = port
    )
    # Create and start tornadio server
    SocketServer(application)
